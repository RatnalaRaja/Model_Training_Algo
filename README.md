
#  Simple Linear Regression 

This README is designed to help you revise and understand **Simple Linear Regression** using a real dataset: height and weight. It includes code breakdown, visual interpretation, and explanation of key metrics.

---

##  Regression Equation

The model tries to find the best straight line:
```
Y = mX + b
```
- `Y`: Predicted value (e.g., Height)
- `X`: Input feature (e.g., Weight)
- `m`: Slope (coefficient)
- `b`: Intercept

---


```
                ^
                |                       Actual Y
                |                        â—
  Height (Y)    |                   â—   â—
                |              â—   |   â—
                |         â—   |   â—
                |    â—    |  â—
                |_________|_____________________>
                        Weight (X)
                        |-----> Predicted Y
```

The model tries to **minimize vertical distances (errors)** between the actual points and the regression line.

---

##  What is RÂ² (R-squared)?

**RÂ² (Coefficient of Determination)** shows how well the line fits the data.

###  Formula:
```
RÂ² = 1 - (SSR / SST)
```
- **SSR**: Sum of Squares of Residuals
- **SST**: Total Sum of Squares

###  Meaning:
- RÂ² = 1 â†’ perfect fit
- RÂ² = 0 â†’ model explains nothing
- RÂ² = 0.8 â†’ 80% of variation in Y is explained by X

---

##  What is Adjusted RÂ²?

Adjusted RÂ² considers the number of predictors and adjusts RÂ² accordingly.

###  Formula:
```
Adjusted RÂ² = 1 - [(1 - RÂ²) * (n - 1) / (n - k - 1)]
```
- `n`: number of samples
- `k`: number of predictors

Use Adjusted RÂ² when you have multiple features or want to prevent overfitting.

---

## ğŸ“ Evaluation Metrics

You used:
- **MSE (Mean Squared Error)**
- **MAE (Mean Absolute Error)**
- **RMSE (Root Mean Squared Error)**

These indicate how far off predictions are from the true values.

---
===================================================================================

#  Multiple Linear Regression 

This README is crafted to help you revise and understand **Multiple Linear Regression** using the California Housing dataset. It breaks down code, key metrics, and explains model behavior in simple terms.

---

##  What is Multiple Linear Regression?

It models the relationship between **one target variable (Y)** and **two or more input features (Xâ‚, Xâ‚‚, ..., Xâ‚™)**:
```
Y = bâ‚€ + bâ‚Xâ‚ + bâ‚‚Xâ‚‚ + ... + bâ‚™Xâ‚™
```

Where:
- `Y`: Predicted output (House Price)
- `Xâ‚, Xâ‚‚, ..., Xâ‚™`: Input features (e.g., MedInc, AveRooms, etc.)
- `bâ‚€`: Intercept
- `bâ‚...bâ‚™`: Coefficients (weights)

---

##  Dataset Used

- **Source**: California Housing dataset from `sklearn.datasets`
- **Target**: `Price` of the house
- **Features**: MedInc, HouseAge, AveRooms, AveOccup, etc.

---

##  Steps You Performed

### 1.  Imported Libraries
```python
from sklearn.datasets import fetch_california_housing
import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt
```

### 2.  Loaded Data
```python
california = fetch_california_housing()
dataset = pd.DataFrame(california.data, columns=california.feature_names)
dataset['Price'] = california.target
```

### 3.  Exploratory Data Analysis
- Used `pairplot()` and `heatmap()` to visualize correlations.

### 4.  Splitting Features
```python
X = dataset.iloc[:, :-1]
Y = dataset.iloc[:, -1]
```

### 5.  Train-Test Split
```python
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=10)
```

### 6.  Feature Scaling
```python
from sklearn.preprocessing import StandardScaler
scalar = StandardScaler()
X_train = scalar.fit_transform(X_train)
X_test = scalar.transform(X_test)
```

### 7.  Model Training
```python
from sklearn.linear_model import LinearRegression
regression = LinearRegression()
regression.fit(X_train, Y_train)
```

### 8.  Prediction
```python
Y_pred = regression.predict(X_test)
```

---

##  Evaluation Metrics

###  Error Metrics
```python
from sklearn.metrics import mean_squared_error, mean_absolute_error
```
- **MSE**: Average squared error
- **MAE**: Average absolute error
- **RMSE**: Root Mean Squared Error

###  RÂ² (Coefficient of Determination)
```python
from sklearn.metrics import r2_score
r2 = r2_score(Y_test, Y_pred)
```

###  Adjusted RÂ²
```python
Adjusted = 1 - (1 - r2) * (len(Y_test) - 1) / (len(Y_test) - X_test.shape[1] - 1)
```

---


